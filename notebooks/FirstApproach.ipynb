{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local notebook - First approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/pmbrull/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/pmbrull/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import spacy\n",
    "from spacy.util import compounding\n",
    "from spacy.util import minibatch\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a3d0a7d5ad</td>\n",
       "      <td>Spent the entire morning in a meeting w/ a ven...</td>\n",
       "      <td>my boss was not happy w/ them. Lots of fun.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251b6a6766</td>\n",
       "      <td>Oh! Good idea about putting them on ice cream</td>\n",
       "      <td>Good</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c9e8d1ef1c</td>\n",
       "      <td>says good (or should i say bad?) afternoon!  h...</td>\n",
       "      <td>says good (or should i say bad?) afternoon!</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f14f087215</td>\n",
       "      <td>i dont think you can vote anymore! i tried</td>\n",
       "      <td>i dont think you can vote anymore!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bf7473b12d</td>\n",
       "      <td>haha better drunken tweeting you mean?</td>\n",
       "      <td>better</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  a3d0a7d5ad  Spent the entire morning in a meeting w/ a ven...   \n",
       "1  251b6a6766      Oh! Good idea about putting them on ice cream   \n",
       "2  c9e8d1ef1c  says good (or should i say bad?) afternoon!  h...   \n",
       "3  f14f087215         i dont think you can vote anymore! i tried   \n",
       "4  bf7473b12d             haha better drunken tweeting you mean?   \n",
       "\n",
       "                                 selected_text sentiment  \n",
       "0  my boss was not happy w/ them. Lots of fun.   neutral  \n",
       "1                                         Good  positive  \n",
       "2  says good (or should i say bad?) afternoon!   neutral  \n",
       "3           i dont think you can vote anymore!  negative  \n",
       "4                                       better  positive  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.read_csv('../data/train.csv')\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27486, 4)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27485, 4)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove missing values\n",
    "raw_df = raw_df.dropna()\n",
    "raw_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11117  8582  7786]\n",
      "['neutral' 'positive' 'negative']\n"
     ]
    }
   ],
   "source": [
    "print(raw_df['sentiment'].value_counts().values)\n",
    "print(raw_df['sentiment'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2fd764f3c8>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.countplot(x='sentiment', data=raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive:  Oh! Good idea about putting them on ice cream\n",
      "Negative:  i dont think you can vote anymore! i tried\n",
      "Neutral: Spent the entire morning in a meeting w/ a vendor, and my boss was not happy w/ them. Lots of fun.  I had other plans for my morning\n"
     ]
    }
   ],
   "source": [
    "# Let's check one example of each:\n",
    "print(\"Positive:\",raw_df[raw_df['sentiment']=='positive']['text'].values[0])\n",
    "print(\"Negative:\",raw_df[raw_df['sentiment']=='negative']['text'].values[0])\n",
    "print(\"Neutral:\",raw_df[raw_df['sentiment']=='neutral']['text'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: Good\n",
      "Negative: i dont think you can vote anymore!\n",
      "Neutral: my boss was not happy w/ them. Lots of fun.\n"
     ]
    }
   ],
   "source": [
    "# We could try to guess which words would be selected in the positive and negative case:\n",
    "# For positive we could say \"Good idea\"\n",
    "# For negative: \"i dont think\"\n",
    "print(\"Positive:\",raw_df[raw_df['sentiment']=='positive']['selected_text'].values[0])\n",
    "print(\"Negative:\",raw_df[raw_df['sentiment']=='negative']['selected_text'].values[0])\n",
    "print(\"Neutral:\",raw_df[raw_df['sentiment']=='neutral']['selected_text'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all in all, somehow accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_words(text, return_list=True):\n",
    "    lower = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower()) # Convert to lower case\n",
    "    words = lower.split() # Split string into words\n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")] # Remove stopwords\n",
    "    # words = [PorterStemmer().stem(w) for w in words] # stem\n",
    "    words = [lemmatizer.lemmatize(w) for w in words]\n",
    "    words = ' '.join(words)\n",
    "    \n",
    "    return words\n",
    "\n",
    "def get_cache(cache_dir, cache_file):\n",
    "    \n",
    "    # If cache_file is not None, try to read from it first\n",
    "    cache_data = None\n",
    "    if cache_file is not None:\n",
    "        try:\n",
    "            with open(os.path.join(cache_dir, cache_file), \"rb\") as f:\n",
    "                cache_data = pd.read_pickle(f)\n",
    "            print(\"Read preprocessed data from cache file:\", cache_file)\n",
    "        except:\n",
    "            pass  # unable to read from cache, but that's okay\n",
    "        \n",
    "    return cache_data\n",
    "\n",
    "def clean_data(df):\n",
    "    clean_text = df['text'].apply(text_to_words)\n",
    "    clean_extracted_text = df['selected_text'].apply(text_to_words)\n",
    "\n",
    "    clean_df = pd.DataFrame({\n",
    "        'text': clean_text,\n",
    "        'selected_text': clean_extracted_text,\n",
    "        'sentiment': df['sentiment']\n",
    "    })\n",
    "    \n",
    "    return clean_df\n",
    "\n",
    "def preprocess_df(df, cache_dir='../cache', cache_file=\"clean_data.pkl\"):\n",
    "    \n",
    "    os.makedirs(cache_dir, exist_ok=True)  # ensure cache directory exists\n",
    "    \n",
    "    cache_data = get_cache(cache_dir, cache_file)\n",
    "    \n",
    "    if cache_data is None:\n",
    "        cache_data = clean_data(df)\n",
    "        cache_data.to_pickle(os.path.join(cache_dir, cache_file))\n",
    "\n",
    "    return cache_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_df = preprocess_df(raw_df)\n",
    "clean_df = preprocess_df(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spent entire morning meeting w vendor bos happ...</td>\n",
       "      <td>bos happy w lot fun</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oh good idea putting ice cream</td>\n",
       "      <td>good</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>say good say bad afternoon http plurk com p wxpdj</td>\n",
       "      <td>say good say bad afternoon</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dont think vote anymore tried</td>\n",
       "      <td>dont think vote anymore</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>haha better drunken tweeting mean</td>\n",
       "      <td>better</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  spent entire morning meeting w vendor bos happ...   \n",
       "1                     oh good idea putting ice cream   \n",
       "2  say good say bad afternoon http plurk com p wxpdj   \n",
       "3                      dont think vote anymore tried   \n",
       "4                  haha better drunken tweeting mean   \n",
       "\n",
       "                selected_text sentiment  \n",
       "0         bos happy w lot fun   neutral  \n",
       "1                        good  positive  \n",
       "2  say good say bad afternoon   neutral  \n",
       "3     dont think vote anymore  negative  \n",
       "4                      better  positive  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(output_dir, nlp, new_model_name):\n",
    "    output_dir = f'../working/{output_dir}'\n",
    "    if output_dir is not None:        \n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        nlp.meta[\"name\"] = new_model_name\n",
    "        nlp.to_disk(output_dir)\n",
    "        print(\"Saved model to\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data, output_dir, n_iter=20, model=None):\n",
    "    \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n",
    "    \n",
    "    if model is not None:\n",
    "        nlp = spacy.load(output_dir)  # load existing spaCy model\n",
    "        print(\"Loaded model '%s'\" % model)\n",
    "    else:\n",
    "        nlp = spacy.blank(\"en\")  # create blank Language class\n",
    "        print(\"Created blank 'en' model\")\n",
    "    \n",
    "    # create the built-in pipeline components and add them to the pipeline\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe(\"ner\")\n",
    "        nlp.add_pipe(ner, last=True)\n",
    "    # otherwise, get it so we can add labels\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "    \n",
    "    # add labels\n",
    "    for _, annotations in train_data:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            ner.add_label(ent[2])\n",
    "\n",
    "    # get names of other pipes to disable them during training\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        # sizes = compounding(1.0, 4.0, 1.001)\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "        if model is None:\n",
    "            nlp.begin_training()\n",
    "        else:\n",
    "            nlp.resume_training()\n",
    "\n",
    "\n",
    "        for itn in tqdm(range(n_iter)):\n",
    "            random.shuffle(train_data)\n",
    "            batches = minibatch(train_data, size=compounding(4.0, 500.0, 1.001))    \n",
    "            losses = {}\n",
    "            for batch in batches:\n",
    "                texts, annotations = zip(*batch)\n",
    "                nlp.update(texts,  # batch of texts\n",
    "                            annotations,  # batch of annotations\n",
    "                            drop=0.5,   # dropout - make it harder to memorise data\n",
    "                            losses=losses, \n",
    "                            )\n",
    "            print(\"Losses\", losses)\n",
    "    save_model(output_dir, nlp, 'st_ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_out_path(sentiment):\n",
    "    model_out_path = None\n",
    "    if sentiment == 'positive':\n",
    "        model_out_path = 'models/model_pos'\n",
    "    elif sentiment == 'negative':\n",
    "        model_out_path = 'models/model_neg'\n",
    "    else:\n",
    "        model_out_path = 'models/model_neu'\n",
    "    return model_out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating data in spacy data input format\n",
    "\n",
    "def get_training_data(df, sentiment):\n",
    "    train_data = []\n",
    "    sentiment_df = df.loc[df['sentiment'] == sentiment]\n",
    "    for index, row in sentiment_df.iterrows():\n",
    "        if row.sentiment == sentiment:\n",
    "            selected_text = row.selected_text\n",
    "            text = row.text\n",
    "            start = text.find(selected_text)\n",
    "            end = start + len(selected_text)\n",
    "            train_data.append((text, {\"entities\": [[start, end, 'selected_text']]}))\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 1/3 [00:27<00:55, 27.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 33832.71321033541}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 2/3 [00:54<00:27, 27.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 31469.29956783507}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:22<00:00, 27.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 29919.369314272495}\n",
      "Saved model to ../working/models/model_pos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Train positive\n",
    "\n",
    "sentiment = 'positive'\n",
    "\n",
    "train_data = get_training_data(raw_df, sentiment)\n",
    "model_path = get_model_out_path(sentiment)\n",
    "\n",
    "train(train_data, model_path, n_iter=3, model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 1/2 [00:26<00:26, 26.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 32653.55848553151}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:55<00:00, 27.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 28817.389152683038}\n",
      "Saved model to ../working/models/model_neg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment = 'negative'\n",
    "\n",
    "train_data = get_training_data(raw_df, sentiment)\n",
    "model_path = get_model_out_path(sentiment)\n",
    "\n",
    "train(train_data, model_path, n_iter=2, model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 1/2 [00:35<00:35, 35.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 7911.316968408187}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:11<00:00, 35.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 5689.52009303563}\n",
      "Saved model to ../working/models/model_neu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment = 'neutral'\n",
    "\n",
    "train_data = get_training_data(raw_df, sentiment)\n",
    "model_path = get_model_out_path(sentiment)\n",
    "\n",
    "train(train_data, model_path, n_iter=2, model=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pos = spacy.load('../working/models/model_pos')\n",
    "model_neg = spacy.load('../working/models/model_neg')\n",
    "model_neu = spacy.load('../working/models/model_neu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_entities(text, model):\n",
    "    doc = model(text)\n",
    "    ent_array = []\n",
    "    for ent in doc.ents:\n",
    "        start = text.find(ent.text)\n",
    "        end = start + len(ent.text)\n",
    "        new_int = [start, end, ent.label_]\n",
    "        if new_int not in ent_array:\n",
    "            ent_array.append([start, end, ent.label_])\n",
    "    selected_text = text[ent_array[0][0]: ent_array[0][1]] if len(ent_array) > 0 else text\n",
    "    return selected_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_texts = []\n",
    "for index, row in test_df.iterrows():\n",
    "    text = row.text\n",
    "    output_str = \"\"\n",
    "    if row.sentiment == 'neutral' or len(text.split()) < 4:\n",
    "        selected_texts.append(text)\n",
    "    elif row.sentiment == 'positive':\n",
    "        selected_texts.append(predict_entities(text, model_pos))\n",
    "    else:\n",
    "        selected_texts.append(predict_entities(text, model_neg))\n",
    "        \n",
    "test_df['selected_text_pred'] = selected_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_terms</th>\n",
       "      <th>selected_text_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251b6a6766</td>\n",
       "      <td>Oh! Good idea about putting them on ice cream</td>\n",
       "      <td>Good</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bf7473b12d</td>\n",
       "      <td>haha better drunken tweeting you mean?</td>\n",
       "      <td>better</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>haha better drunken tweeting you mean?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2ab82634d5</td>\n",
       "      <td>had an awsome salad! I recommend getting the S...</td>\n",
       "      <td>had an awsome salad!</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>had an awsome salad! I recommend getting the S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a5a1c996c0</td>\n",
       "      <td>fine! Going to do my big walk today 20 or so ...</td>\n",
       "      <td>fine!</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>fine!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a182b2638e</td>\n",
       "      <td>Thank a yoou  how are you? #TwitterTakeover</td>\n",
       "      <td>Thank</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>Thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bc0f2cb758</td>\n",
       "      <td>Have just bought a TV tuner for my laptop.  He...</td>\n",
       "      <td>Have just bought a TV tuner for my laptop.  He...</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>deserve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22744e80f7</td>\n",
       "      <td>12:46AM. HAppy birthday little sister of mine....</td>\n",
       "      <td>HAppy birthday little sister of mine.</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>HAppy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>e487233140</td>\n",
       "      <td>aaawww  no worries fresh start to work on gro...</td>\n",
       "      <td>aaawww  no worries</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>aaawww  no worries fresh start to work on gro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>01cfa3807e</td>\n",
       "      <td>is sooo tired and too busy to tweet  im glad t...</td>\n",
       "      <td>glad</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>glad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>a6c77ff610</td>\n",
       "      <td>Just watched &amp;quot;Marley &amp;amp; Me.&amp;quot; Cute...</td>\n",
       "      <td>mp; Me</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>Cute</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        textID                                               text  \\\n",
       "1   251b6a6766      Oh! Good idea about putting them on ice cream   \n",
       "4   bf7473b12d             haha better drunken tweeting you mean?   \n",
       "6   2ab82634d5  had an awsome salad! I recommend getting the S...   \n",
       "7   a5a1c996c0   fine! Going to do my big walk today 20 or so ...   \n",
       "8   a182b2638e        Thank a yoou  how are you? #TwitterTakeover   \n",
       "13  bc0f2cb758  Have just bought a TV tuner for my laptop.  He...   \n",
       "23  22744e80f7  12:46AM. HAppy birthday little sister of mine....   \n",
       "24  e487233140   aaawww  no worries fresh start to work on gro...   \n",
       "26  01cfa3807e  is sooo tired and too busy to tweet  im glad t...   \n",
       "29  a6c77ff610  Just watched &quot;Marley &amp; Me.&quot; Cute...   \n",
       "\n",
       "                                        selected_text sentiment  \\\n",
       "1                                                Good  positive   \n",
       "4                                              better  positive   \n",
       "6                                had an awsome salad!  positive   \n",
       "7                                               fine!  positive   \n",
       "8                                               Thank  positive   \n",
       "13  Have just bought a TV tuner for my laptop.  He...  positive   \n",
       "23              HAppy birthday little sister of mine.  positive   \n",
       "24                                 aaawww  no worries  positive   \n",
       "26                                               glad  positive   \n",
       "29                                             mp; Me  positive   \n",
       "\n",
       "   sentiment_terms                                 selected_text_pred  \n",
       "1                                                                Good  \n",
       "4                              haha better drunken tweeting you mean?  \n",
       "6                   had an awsome salad! I recommend getting the S...  \n",
       "7                                                               fine!  \n",
       "8                                                               Thank  \n",
       "13                                                            deserve  \n",
       "23                                                              HAppy  \n",
       "24                   aaawww  no worries fresh start to work on gro...  \n",
       "26                                                               glad  \n",
       "29                                                               Cute  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[test_df['sentiment'] == 'positive'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(str1, str2): \n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_terms</th>\n",
       "      <th>selected_text_pred</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a3d0a7d5ad</td>\n",
       "      <td>Spent the entire morning in a meeting w/ a ven...</td>\n",
       "      <td>my boss was not happy w/ them. Lots of fun.</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>Spent the entire morning in a meeting w/ a ven...</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251b6a6766</td>\n",
       "      <td>Oh! Good idea about putting them on ice cream</td>\n",
       "      <td>Good</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>Good</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c9e8d1ef1c</td>\n",
       "      <td>says good (or should i say bad?) afternoon!  h...</td>\n",
       "      <td>says good (or should i say bad?) afternoon!</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td>says good (or should i say bad?) afternoon!  h...</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f14f087215</td>\n",
       "      <td>i dont think you can vote anymore! i tried</td>\n",
       "      <td>i dont think you can vote anymore!</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "      <td>i dont think you can vote anymore! i tried</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bf7473b12d</td>\n",
       "      <td>haha better drunken tweeting you mean?</td>\n",
       "      <td>better</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>haha better drunken tweeting you mean?</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  a3d0a7d5ad  Spent the entire morning in a meeting w/ a ven...   \n",
       "1  251b6a6766      Oh! Good idea about putting them on ice cream   \n",
       "2  c9e8d1ef1c  says good (or should i say bad?) afternoon!  h...   \n",
       "3  f14f087215         i dont think you can vote anymore! i tried   \n",
       "4  bf7473b12d             haha better drunken tweeting you mean?   \n",
       "\n",
       "                                 selected_text sentiment sentiment_terms  \\\n",
       "0  my boss was not happy w/ them. Lots of fun.   neutral                   \n",
       "1                                         Good  positive                   \n",
       "2  says good (or should i say bad?) afternoon!   neutral                   \n",
       "3           i dont think you can vote anymore!  negative                   \n",
       "4                                       better  positive                   \n",
       "\n",
       "                                  selected_text_pred     score  \n",
       "0  Spent the entire morning in a meeting w/ a ven...  0.416667  \n",
       "1                                               Good  1.000000  \n",
       "2  says good (or should i say bad?) afternoon!  h...  0.888889  \n",
       "3         i dont think you can vote anymore! i tried  0.875000  \n",
       "4             haha better drunken tweeting you mean?  0.166667  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['score'] = test_df[['selected_text','selected_text_pred']].apply(lambda x: jaccard(*x), axis=1)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6457666667680935"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final Score\n",
    "test_df['score'].sum() / test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_terms</th>\n",
       "      <th>selected_text_pred</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251b6a6766</td>\n",
       "      <td>Oh! Good idea about putting them on ice cream</td>\n",
       "      <td>Good</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>Good</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bf7473b12d</td>\n",
       "      <td>haha better drunken tweeting you mean?</td>\n",
       "      <td>better</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>haha better drunken tweeting you mean?</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2ab82634d5</td>\n",
       "      <td>had an awsome salad! I recommend getting the S...</td>\n",
       "      <td>had an awsome salad!</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>had an awsome salad! I recommend getting the S...</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a5a1c996c0</td>\n",
       "      <td>fine! Going to do my big walk today 20 or so ...</td>\n",
       "      <td>fine!</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>fine!</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a182b2638e</td>\n",
       "      <td>Thank a yoou  how are you? #TwitterTakeover</td>\n",
       "      <td>Thank</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>Thank</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bc0f2cb758</td>\n",
       "      <td>Have just bought a TV tuner for my laptop.  He...</td>\n",
       "      <td>Have just bought a TV tuner for my laptop.  He...</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>deserve</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22744e80f7</td>\n",
       "      <td>12:46AM. HAppy birthday little sister of mine....</td>\n",
       "      <td>HAppy birthday little sister of mine.</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>HAppy</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>e487233140</td>\n",
       "      <td>aaawww  no worries fresh start to work on gro...</td>\n",
       "      <td>aaawww  no worries</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>aaawww  no worries fresh start to work on gro...</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>01cfa3807e</td>\n",
       "      <td>is sooo tired and too busy to tweet  im glad t...</td>\n",
       "      <td>glad</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>glad</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>a6c77ff610</td>\n",
       "      <td>Just watched &amp;quot;Marley &amp;amp; Me.&amp;quot; Cute...</td>\n",
       "      <td>mp; Me</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>Cute</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4ce78f6e92</td>\n",
       "      <td>oh he is so cute... is he in uniteddogs.com? ...</td>\n",
       "      <td>cute.</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>oh he is so cute... is he in uniteddogs.com? ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>9dd2edd0fd</td>\n",
       "      <td>i'm actually starting to quite like lily allen...</td>\n",
       "      <td>o quite like lily allen and her music, to be h...</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>i'm actually starting to quite like lily allen...</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>daadcab8af</td>\n",
       "      <td>I'm sooo HAPPY Demi's back on twitter!</td>\n",
       "      <td>I'm sooo HAPPY De</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>HAPPY</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ebe46589f3</td>\n",
       "      <td>That would be most welcome</td>\n",
       "      <td>That would be most welcome</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>That would be most welcome</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>7f0c862bad</td>\n",
       "      <td>Why do weddings on TV make me cry? Is it just ...</td>\n",
       "      <td>happy</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>happy</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4f26fc0981</td>\n",
       "      <td>aw, that's cute</td>\n",
       "      <td>aw, that's cute</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>aw, that's cute</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>fe98872319</td>\n",
       "      <td>I saw them a few on this tour a few months ag...</td>\n",
       "      <td>So good! Glad you finally got to see them</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>Glad</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>d11234ed68</td>\n",
       "      <td>Heading to the U of Utah hospital. Have a grea...</td>\n",
       "      <td>Have a great day everyone</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>great</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0bc6d79c40</td>\n",
       "      <td>Today seems like it should be a good day! Even...</td>\n",
       "      <td>Today seems like it should be a good day!</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>good</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0338930089</td>\n",
       "      <td>so most kids love my dark hair some say that I...</td>\n",
       "      <td>love</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>love</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        textID                                               text  \\\n",
       "1   251b6a6766      Oh! Good idea about putting them on ice cream   \n",
       "4   bf7473b12d             haha better drunken tweeting you mean?   \n",
       "6   2ab82634d5  had an awsome salad! I recommend getting the S...   \n",
       "7   a5a1c996c0   fine! Going to do my big walk today 20 or so ...   \n",
       "8   a182b2638e        Thank a yoou  how are you? #TwitterTakeover   \n",
       "13  bc0f2cb758  Have just bought a TV tuner for my laptop.  He...   \n",
       "23  22744e80f7  12:46AM. HAppy birthday little sister of mine....   \n",
       "24  e487233140   aaawww  no worries fresh start to work on gro...   \n",
       "26  01cfa3807e  is sooo tired and too busy to tweet  im glad t...   \n",
       "29  a6c77ff610  Just watched &quot;Marley &amp; Me.&quot; Cute...   \n",
       "32  4ce78f6e92   oh he is so cute... is he in uniteddogs.com? ...   \n",
       "34  9dd2edd0fd  i'm actually starting to quite like lily allen...   \n",
       "37  daadcab8af             I'm sooo HAPPY Demi's back on twitter!   \n",
       "40  ebe46589f3                         That would be most welcome   \n",
       "41  7f0c862bad  Why do weddings on TV make me cry? Is it just ...   \n",
       "47  4f26fc0981                                    aw, that's cute   \n",
       "49  fe98872319   I saw them a few on this tour a few months ag...   \n",
       "51  d11234ed68  Heading to the U of Utah hospital. Have a grea...   \n",
       "54  0bc6d79c40  Today seems like it should be a good day! Even...   \n",
       "62  0338930089  so most kids love my dark hair some say that I...   \n",
       "\n",
       "                                        selected_text sentiment  \\\n",
       "1                                                Good  positive   \n",
       "4                                              better  positive   \n",
       "6                                had an awsome salad!  positive   \n",
       "7                                               fine!  positive   \n",
       "8                                               Thank  positive   \n",
       "13  Have just bought a TV tuner for my laptop.  He...  positive   \n",
       "23              HAppy birthday little sister of mine.  positive   \n",
       "24                                 aaawww  no worries  positive   \n",
       "26                                               glad  positive   \n",
       "29                                             mp; Me  positive   \n",
       "32                                              cute.  positive   \n",
       "34  o quite like lily allen and her music, to be h...  positive   \n",
       "37                                  I'm sooo HAPPY De  positive   \n",
       "40                         That would be most welcome  positive   \n",
       "41                                              happy  positive   \n",
       "47                                    aw, that's cute  positive   \n",
       "49          So good! Glad you finally got to see them  positive   \n",
       "51                          Have a great day everyone  positive   \n",
       "54          Today seems like it should be a good day!  positive   \n",
       "62                                               love  positive   \n",
       "\n",
       "   sentiment_terms                                 selected_text_pred  \\\n",
       "1                                                                Good   \n",
       "4                              haha better drunken tweeting you mean?   \n",
       "6                   had an awsome salad! I recommend getting the S...   \n",
       "7                                                               fine!   \n",
       "8                                                               Thank   \n",
       "13                                                            deserve   \n",
       "23                                                              HAppy   \n",
       "24                   aaawww  no worries fresh start to work on gro...   \n",
       "26                                                               glad   \n",
       "29                                                               Cute   \n",
       "32                   oh he is so cute... is he in uniteddogs.com? ...   \n",
       "34                  i'm actually starting to quite like lily allen...   \n",
       "37                                                              HAPPY   \n",
       "40                                         That would be most welcome   \n",
       "41                                                              happy   \n",
       "47                                                    aw, that's cute   \n",
       "49                                                               Glad   \n",
       "51                                                              great   \n",
       "54                                                               good   \n",
       "62                                                               love   \n",
       "\n",
       "       score  \n",
       "1   1.000000  \n",
       "4   0.166667  \n",
       "6   0.363636  \n",
       "7   1.000000  \n",
       "8   1.000000  \n",
       "13  0.071429  \n",
       "23  0.166667  \n",
       "24  0.250000  \n",
       "26  1.000000  \n",
       "29  0.000000  \n",
       "32  0.000000  \n",
       "34  0.714286  \n",
       "37  0.250000  \n",
       "40  1.000000  \n",
       "41  1.000000  \n",
       "47  1.000000  \n",
       "49  0.111111  \n",
       "51  0.200000  \n",
       "54  0.111111  \n",
       "62  1.000000  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[test_df['sentiment'] == 'positive'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
