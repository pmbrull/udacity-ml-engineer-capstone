{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local notebook - First approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/pmbrull/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import spacy\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a3d0a7d5ad</td>\n",
       "      <td>Spent the entire morning in a meeting w/ a ven...</td>\n",
       "      <td>my boss was not happy w/ them. Lots of fun.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251b6a6766</td>\n",
       "      <td>Oh! Good idea about putting them on ice cream</td>\n",
       "      <td>Good</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c9e8d1ef1c</td>\n",
       "      <td>says good (or should i say bad?) afternoon!  h...</td>\n",
       "      <td>says good (or should i say bad?) afternoon!</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f14f087215</td>\n",
       "      <td>i dont think you can vote anymore! i tried</td>\n",
       "      <td>i dont think you can vote anymore!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bf7473b12d</td>\n",
       "      <td>haha better drunken tweeting you mean?</td>\n",
       "      <td>better</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  a3d0a7d5ad  Spent the entire morning in a meeting w/ a ven...   \n",
       "1  251b6a6766      Oh! Good idea about putting them on ice cream   \n",
       "2  c9e8d1ef1c  says good (or should i say bad?) afternoon!  h...   \n",
       "3  f14f087215         i dont think you can vote anymore! i tried   \n",
       "4  bf7473b12d             haha better drunken tweeting you mean?   \n",
       "\n",
       "                                 selected_text sentiment  \n",
       "0  my boss was not happy w/ them. Lots of fun.   neutral  \n",
       "1                                         Good  positive  \n",
       "2  says good (or should i say bad?) afternoon!   neutral  \n",
       "3           i dont think you can vote anymore!  negative  \n",
       "4                                       better  positive  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.read_csv('../data/train.csv')\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27486, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27485, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove missing values\n",
    "raw_df = raw_df.dropna()\n",
    "raw_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11117  8582  7786]\n",
      "['neutral' 'positive' 'negative']\n"
     ]
    }
   ],
   "source": [
    "print(raw_df['sentiment'].value_counts().values)\n",
    "print(raw_df['sentiment'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2fe48604a8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.countplot(x='sentiment', data=raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive:  Oh! Good idea about putting them on ice cream\n",
      "Negative:  i dont think you can vote anymore! i tried\n",
      "Neutral: Spent the entire morning in a meeting w/ a vendor, and my boss was not happy w/ them. Lots of fun.  I had other plans for my morning\n"
     ]
    }
   ],
   "source": [
    "# Let's check one example of each:\n",
    "print(\"Positive:\",raw_df[raw_df['sentiment']=='positive']['text'].values[0])\n",
    "print(\"Negative:\",raw_df[raw_df['sentiment']=='negative']['text'].values[0])\n",
    "print(\"Neutral:\",raw_df[raw_df['sentiment']=='neutral']['text'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: Good\n",
      "Negative: i dont think you can vote anymore!\n",
      "Neutral: my boss was not happy w/ them. Lots of fun.\n"
     ]
    }
   ],
   "source": [
    "# We could try to guess which words would be selected in the positive and negative case:\n",
    "# For positive we could say \"Good idea\"\n",
    "# For negative: \"i dont think\"\n",
    "print(\"Positive:\",raw_df[raw_df['sentiment']=='positive']['selected_text'].values[0])\n",
    "print(\"Negative:\",raw_df[raw_df['sentiment']=='negative']['selected_text'].values[0])\n",
    "print(\"Neutral:\",raw_df[raw_df['sentiment']=='neutral']['selected_text'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all in all, somehow accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, int found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-41b9a2b9e899>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, int found"
     ]
    }
   ],
   "source": [
    "' '.join([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_words(text, return_list=True):\n",
    "    lower = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower()) # Convert to lower case\n",
    "    words = lower.split() # Split string into words\n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")] # Remove stopwords\n",
    "    words = [PorterStemmer().stem(w) for w in words] # stem\n",
    "    if not return_list:\n",
    "        words = ' '.join(words)\n",
    "    \n",
    "    return words\n",
    "\n",
    "def get_cache(cache_dir, cache_file):\n",
    "    \n",
    "    # If cache_file is not None, try to read from it first\n",
    "    cache_data = None\n",
    "    if cache_file is not None:\n",
    "        try:\n",
    "            with open(os.path.join(cache_dir, cache_file), \"rb\") as f:\n",
    "                cache_data = pd.read_pickle(f)\n",
    "            print(\"Read preprocessed data from cache file:\", cache_file)\n",
    "        except:\n",
    "            pass  # unable to read from cache, but that's okay\n",
    "        \n",
    "    return cache_data\n",
    "\n",
    "def clean_data(df):\n",
    "    clean_text = df['text'].apply(text_to_words)\n",
    "    clean_extracted_text = df['selected_text'].apply(text_to_words)\n",
    "\n",
    "    clean_df = pd.DataFrame({\n",
    "        'text': clean_text,\n",
    "        'selected_text': clean_extracted_text,\n",
    "        'sentiment': df['sentiment']\n",
    "    })\n",
    "    \n",
    "    return clean_df\n",
    "\n",
    "def preprocess_df(df, cache_dir='../cache', cache_file=\"clean_data.pkl\", return_list=True):\n",
    "    \n",
    "    os.makedirs(cache_dir, exist_ok=True)  # ensure cache directory exists\n",
    "    \n",
    "    cache_data = get_cache(cache_dir, cache_file)\n",
    "    \n",
    "    if cache_data is None:\n",
    "        cache_data = clean_data(df, return_list)\n",
    "        cache_data.to_pickle(os.path.join(cache_dir, cache_file))\n",
    "\n",
    "    return cache_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_df = preprocess_df(raw_df)\n",
    "clean_df = preprocess_df(raw_df, '../cache', 'clean_data_nolist.pkl', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[spent, entir, morn, meet, w, vendor, boss, ha...</td>\n",
       "      <td>[boss, happi, w, lot, fun]</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[oh, good, idea, put, ice, cream]</td>\n",
       "      <td>[good]</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[say, good, say, bad, afternoon, http, plurk, ...</td>\n",
       "      <td>[say, good, say, bad, afternoon]</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[dont, think, vote, anymor, tri]</td>\n",
       "      <td>[dont, think, vote, anymor]</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[haha, better, drunken, tweet, mean]</td>\n",
       "      <td>[better]</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  [spent, entir, morn, meet, w, vendor, boss, ha...   \n",
       "1                  [oh, good, idea, put, ice, cream]   \n",
       "2  [say, good, say, bad, afternoon, http, plurk, ...   \n",
       "3                   [dont, think, vote, anymor, tri]   \n",
       "4               [haha, better, drunken, tweet, mean]   \n",
       "\n",
       "                      selected_text sentiment  \n",
       "0        [boss, happi, w, lot, fun]   neutral  \n",
       "1                            [good]  positive  \n",
       "2  [say, good, say, bad, afternoon]   neutral  \n",
       "3       [dont, think, vote, anymor]  negative  \n",
       "4                          [better]  positive  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(output_dir, nlp, new_model_name):\n",
    "    output_dir = f'../working/{output_dir}'\n",
    "    if output_dir is not None:        \n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        nlp.meta[\"name\"] = new_model_name\n",
    "        nlp.to_disk(output_dir)\n",
    "        print(\"Saved model to\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data, output_dir, n_iter=20, model=None):\n",
    "    \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n",
    "    \n",
    "    if model is not None:\n",
    "        nlp = spacy.load(output_dir)  # load existing spaCy model\n",
    "        print(\"Loaded model '%s'\" % model)\n",
    "    else:\n",
    "        nlp = spacy.blank(\"en\")  # create blank Language class\n",
    "        print(\"Created blank 'en' model\")\n",
    "    \n",
    "    # create the built-in pipeline components and add them to the pipeline\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe(\"ner\")\n",
    "        nlp.add_pipe(ner, last=True)\n",
    "    # otherwise, get it so we can add labels\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "    \n",
    "    # add labels\n",
    "    for _, annotations in train_data:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            ner.add_label(ent[2])\n",
    "\n",
    "    # get names of other pipes to disable them during training\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        # sizes = compounding(1.0, 4.0, 1.001)\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "        if model is None:\n",
    "            nlp.begin_training()\n",
    "        else:\n",
    "            nlp.resume_training()\n",
    "\n",
    "\n",
    "        for itn in tqdm(range(n_iter)):\n",
    "            random.shuffle(train_data)\n",
    "            batches = minibatch(train_data, size=compounding(4.0, 500.0, 1.001))    \n",
    "            losses = {}\n",
    "            for batch in batches:\n",
    "                texts, annotations = zip(*batch)\n",
    "                nlp.update(texts,  # batch of texts\n",
    "                            annotations,  # batch of annotations\n",
    "                            drop=0.5,   # dropout - make it harder to memorise data\n",
    "                            losses=losses, \n",
    "                            )\n",
    "            print(\"Losses\", losses)\n",
    "    save_model(output_dir, nlp, 'st_ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_out_path(sentiment):\n",
    "    model_out_path = None\n",
    "    if sentiment == 'positive':\n",
    "        model_out_path = 'models/model_pos'\n",
    "    elif sentiment == 'negative':\n",
    "        model_out_path = 'models/model_neg'\n",
    "    else:\n",
    "        model_out_path = 'models/model_neu'\n",
    "    return model_out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating data in spacy data input format\n",
    "\n",
    "def get_training_data(df, sentiment):\n",
    "    train_data = []\n",
    "    sentiment_df = df.loc[df['sentiment'] == sentiment]\n",
    "    for index, row in sentiment_df.iterrows():\n",
    "        if row.sentiment == sentiment:\n",
    "            selected_text = row.selected_text\n",
    "            text = row.text\n",
    "            start = text.find(selected_text)\n",
    "            end = start + len(selected_text)\n",
    "            train_data.append((text, {\"entities\": [[start, end, 'selected_text']]}))\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_df = clean_df\n",
    "spacy_df['text'] = spacy_df['text'].join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-9a8c08d3d2cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msentiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'positive'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_out_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-73-3590f2873c9c>\u001b[0m in \u001b[0;36mget_training_data\u001b[0;34m(df, sentiment)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mselected_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselected_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"entities\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'selected_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "## Train positive\n",
    "\n",
    "sentiment = 'positive'\n",
    "\n",
    "train_data = get_training_data(clean_df, sentiment)\n",
    "model_path = get_model_out_path(sentiment)\n",
    "\n",
    "# for demo purpose i am just training the model for 2 iterations, feel free to experiment.\n",
    "train(train_data, model_path, n_iter=2, model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
